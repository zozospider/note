
# 深入 Kafka

`92`:
__集群成员关系__
__控制器__: 控制器其实就是 broker, Kafka 使用 Zookeeper 的临时节点来选举控制器，控制器负责在节点加入或离开集群时进行分区Leader选举。控制器使用 epoch 来避免“脑裂” 。

`94`: __复制__
- Leader replication: 为了保证一致性，所有生产者请求和消费者请求都会经过这个副本。通过查看每个Follower请求的最新偏移 ， Leader 就会知道每个Follower复制的进度。
- Follower replication: 它们唯一的任务就是从Leader那里复制消息，保持与Leader一致的状态。如果Leader发生崩渍，其中的Follower会被提升为新Leader。持续请求得到的最新悄息副本被称为同步的副本。在 Leader 发生失效时，只有同步副本才有可能被选为新 Leader 。
__首选首领__: ?

`97`: __生产请求__: 悄息被写入本地磁盘。在 Linux 系统上，消息会被写到文件系统缓存里，并不保证它们何时会被刷新到磁盘上。Kafka 不会一直等待数据被写到磁盘上一一它依赖复制功能来保证消息的持久性。
`97`: __获取请求__: Kafka 使用零复制技术向客户端发送消息, 也就是说, Kafka 直接把消息从文件（或者更确切地说是 Linux 文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区。这是 Kafka 与其他大部分数据库系统不一样的地方，其他数据库在将数据发送给客户端之前会先把它们保存在本地缓存里。这项技术避免了字节复制，也不需要管理内存缓冲区，从而获得更好的性能。

`98`: 一致性 & 高水位: 并不是所有保存在分区首领上的数据都可以被客户端读取。大部分客户端只能读取已经被写入所有同步副本的悄息。在消息还没有被写入所有同步副本之前，是不会发送给消费者的。
因为还没有被足够多副本复制的消息被认为是“不安全”的一一如果首领发生崩愤，另一个副本成为新首领，那么这些消息就丢失了。如果我们允许消费者读取这些消息，可能就会破一致性。
所以，我们会等到所有同步副本复制了这些消息，才允许消费者读取它们。

`100`: __物理存储__: Kafka 的基本存储单元是分区。分区无住在多个 broker 间进行再细分，也无法在同一个 broker 的多个磁盘上进行再细分。 所以，分区的大小受到单个挂载点可用空间的限制.
用于存储分区的目录清单 `log.dirs`: 该参数一般会包含每个挂载点的目录。

`100`: __分区分配__: 1. 在 broker 间平均地分布分区副本。2. 确保每个分区的每个副本分布在不同的 broker 上。3. 如果为 broker 指定了机架信息，那么尽可能把每个分区的副本分配到不同机架的 broker 上。
`101`: __目录分配__: 规则: 计算每个目录里的分区数量，新的分区总是被添加到数量最小的那个目录里。也就是说，如果添加了一个新磁盘，所有新的分区都会被创建到这个磁盘上。

`102`: __文件管理__: 我们把分区分成若个片段, 默认情况下，每个片段包含 lGB 或一周的数据。当前正在写入数据的片段叫作活跃片段。活动片段永远不会被删除。
`102`: __文件格式__: 保存在磁盘上的数据格式与从生产者发送过来或者发送给消费者的悄息格式是一样的。Kafka 可以使用零复制技术给消费者发送消息，同时避免了对生产者已经压缩过的消息进行解压和再压缩。
除了键、值和偏移量外， 消息里还包含了消息大小、校 和、消息格式版本号、压缩算能(Snappy GZip LZ4 ）和时间戳（在 0.10.0 版本里引入的）
如果生产者发送的是压缩过的消息，那么同一个批次的消息会被压缩在一起，被当作“包装消息”进行发送。消费者在解压这个消息之后，会看到整个批次的消息。
如果在生产者端使用了压缩功能（极力推荐），那么发送的批次越大，就意味着在网络传输和磁盘存储方面会获得越好的压缩性能。

`103`: __索引__: 索引把偏移量映射到片段文件和偏移量在文件里的位置。索引也被分成片段，所以在删除消息时，也可以删除相应的索引。
`103`: __清理__, __清理的工作原理__, __被删除的事件__, __何时会清理主题__ ?


