
# 五. 深入 Kafka

`92`:
__集群成员关系__
__控制器__: 控制器其实就是 broker, Kafka 使用 Zookeeper 的临时节点来选举控制器，控制器负责在节点加入或离开集群时进行分区Leader选举。控制器使用 epoch 来避免“脑裂” 。

`94`: __复制__
- Leader replication: 为了保证一致性，所有生产者请求和消费者请求都会经过这个副本。通过查看每个Follower请求的最新偏移 ， Leader 就会知道每个Follower复制的进度。
- Follower replication: 它们唯一的任务就是从Leader那里复制消息，保持与Leader一致的状态。如果Leader发生崩渍，其中的Follower会被提升为新Leader。持续请求得到的最新悄息副本被称为同步的副本。在 Leader 发生失效时，只有同步副本才有可能被选为新 Leader 。
__首选首领__: ?

`97`: __生产请求__: 悄息被写入本地磁盘。在 Linux 系统上，消息会被写到文件系统缓存里，并不保证它们何时会被刷新到磁盘上。Kafka 不会一直等待数据被写到磁盘上一一它依赖复制功能来保证消息的持久性。
`97`: __获取请求__: Kafka 使用零复制技术向客户端发送消息, 也就是说, Kafka 直接把消息从文件（或者更确切地说是 Linux 文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区。这是 Kafka 与其他大部分数据库系统不一样的地方，其他数据库在将数据发送给客户端之前会先把它们保存在本地缓存里。这项技术避免了字节复制，也不需要管理内存缓冲区，从而获得更好的性能。

`98`: 一致性 & 高水位: 并不是所有保存在分区首领上的数据都可以被客户端读取。大部分客户端只能读取已经被写入所有同步副本的悄息。在消息还没有被写入所有同步副本之前，是不会发送给消费者的。
因为还没有被足够多副本复制的消息被认为是“不安全”的一一如果首领发生崩愤，另一个副本成为新首领，那么这些消息就丢失了。如果我们允许消费者读取这些消息，可能就会破一致性。
所以，我们会等到所有同步副本复制了这些消息，才允许消费者读取它们。

`100`: __物理存储__: Kafka 的基本存储单元是分区。分区无住在多个 broker 间进行再细分，也无法在同一个 broker 的多个磁盘上进行再细分。 所以，分区的大小受到单个挂载点可用空间的限制.
用于存储分区的目录清单 `log.dirs`: 该参数一般会包含每个挂载点的目录。

`100`: __分区分配__: 1. 在 broker 间平均地分布分区副本。2. 确保每个分区的每个副本分布在不同的 broker 上。3. 如果为 broker 指定了机架信息，那么尽可能把每个分区的副本分配到不同机架的 broker 上。
`101`: __目录分配__: 规则: 计算每个目录里的分区数量，新的分区总是被添加到数量最小的那个目录里。也就是说，如果添加了一个新磁盘，所有新的分区都会被创建到这个磁盘上。

`102`: __文件管理__: 我们把分区分成若个片段, 默认情况下，每个片段包含 lGB 或一周的数据。当前正在写入数据的片段叫作活跃片段。活动片段永远不会被删除。
`102`: __文件格式__: 保存在磁盘上的数据格式与从生产者发送过来或者发送给消费者的悄息格式是一样的。Kafka 可以使用零复制技术给消费者发送消息，同时避免了对生产者已经压缩过的消息进行解压和再压缩。
除了键、值和偏移量外， 消息里还包含了消息大小、校 和、消息格式版本号、压缩算能(Snappy GZip LZ4 ）和时间戳（在 0.10.0 版本里引入的）
如果生产者发送的是压缩过的消息，那么同一个批次的消息会被压缩在一起，被当作“包装消息”进行发送。消费者在解压这个消息之后，会看到整个批次的消息。
如果在生产者端使用了压缩功能（极力推荐），那么发送的批次越大，就意味着在网络传输和磁盘存储方面会获得越好的压缩性能。

`103`: __索引__: 索引把偏移量映射到片段文件和偏移量在文件里的位置。索引也被分成片段，所以在删除消息时，也可以删除相应的索引。
`103`: __清理__, __清理的工作原理__, __被删除的事件__, __何时会清理主题__ ?

---

# 六. 可靠的数据传递

`87 6.1`: __可靠性保证__: Kafka 可以保证分区消息的顺序。只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“已提交”的。只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。消费者只能读取已经提交的消息。

`88 6.2`: __复制__: Kafka 的复制机制和分区的多副本架构是 Kafka 可靠性保证的核心。
Kafka 的主题被分为多个分区 ，分区是基本的数据块。分区存储在单个磁盘上， Kafka 可以保证分区里的事件是有序的，
分区首领是同步副本，而对于跟随者副本来说，它需要满足以下条件才能被认为是同步的。
1. 与Zookeeper 之间有一个活跃的会话，也就是说，它在过去的“（可配置）内向 Zookeeper 发送过心跳。
2. 在过去的 10s 内（可配置）从首领那里获取过消息。
3. 在过去的 10s 内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，它还必须是儿乎零延迟的。
如果跟随者副本不能满足以上任何一点，比如与 Zookeeper 断开连接，或者不再获取新消息，或者获取消息滞后了 10s 以上，那么它就被认为是不同步的。一个不同步的副本通过 Zookeeper 重新建立连接，井从首领那里获取最新消息，可以重新变成同步的。

`89 6.2` 非同步副本 (Kafka 测试时出现的断开 ZooKeeper 连接情况): 如果一个或多个副本在同步和非同步状态之间快速切换，说明集群内部出现了问题，通常是 Java 不恰当的垃圾回收配置导致的。不恰当的垃圾回收配置会造成几秒钟的停顿，从而让 broker 与 Zookeeper之间断开连接，最后变成不同步的，进而发生状态切换。

一个滞后的同步副本会导致生产者和消费者变慢。虽然非同步副本同样滞后，但它并不会对性能产生任何影响。

`89 6.3`: __broker配置__: broker 有 3 个配置参数会影响 Kafka 消息存储的可靠性:
__复制系数__: `replication.factor` 默认 3, 即使是在主题创建之后，也可以通过新增或移除副本来改变复制系数。我们一般会在可用性和存储硬件之间作出权衡。复制系数设为 3。在大多数情况下，这已经足够安全了，不过我们也见过有些银行使用 5 个副本。建议把 broker 分布在多个不同的机架上，并使用 `broker.ack` 参数来为每个 broker 配置所在机架的名字。如果配置了机架的名字， Kafka 会保证分区的副本被分布在多个机架上，从而获得更高的可用性。
__不完全的 Leader 选举__: 简而言之，如果我们允许不同步的副本成为首领，那么就要承担丢失数据和出现数据不一致的风险。 如果不允许它们成为首领，那么就要接受较低的可用性，因为我们必须等待原先的首领恢复到可用状态。`unclean.leader.election.enable` true/false 控制.
__最少同步副本__: `min.insync.replicas` 消息只有在被写入到所有同步副本之后才被认为是已提交的. 要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大的值。


`92 6.4`: __在可靠的系统里使用生产者__: 每个使用 Kafka 的开发人员都要注意两件事情: 根据可靠性需求配置恰当的 acks 值。在参数配置和代码里正确处理错误。
__发送确认__: 生产者可以选择 3 种不同的确认模式: acks=0, acks=1, acks=all.
__配置生产者的重试参数__: 可重试错误, 不可重试错误. 当前的 Kafka 版本 (0.10.0) 无法保证每个消息“只被保存一次”。现实中的很多应用程序在消息里加入唯一标识符，用于检测重复消息，消费者在读取消息时可以对它们进行清理。还要有一些应用程序可以做到消息的“幕等”，也就说，即使出现了重复消息，也不会对处理结果的正确性造成负面影响。例如，消息 “这个账号里有 110 美元”就是幕等的。
__额外的错误处理__: 开发人员仍然需要处理其他类型的错误: 不可重试的 broker 错误，例如消息大小错误、认证错误等. 在消息发送之前发生的错误，例如序列化错误. 在生产者达到重试次数上限时或者在消息占用的内存达到上限时发生的错误。如果错误处理只是为了重试发送消息，那么最好还是使用生产者内置的重试机制。

`94 6.5`: __在可靠的系统里使用消费者__: 只有那些被提交到 Kafka 的数据，也就是那些已经被写入所有同步副本的数据，对消费者是可用的，这意味着消费者得到的消息已经具备了一致性。消费者唯一要做的是跟踪哪些消息是已经读取过的，哪些是还没有读取过的。
__消费者的可靠性配置__: `group.id`, `auto.offset.reset`, `enable.auto.commit`, `auto.commit.interval.ms`.
__显式提交偏移量__: 总是在处理完事件后再提交偏移量; 提交频度是性能和重复消息数量之间的权衡; 确保对提交的偏移量心里有数; 再均衡; 消费者可能需要重试; 消费者可能需要重试; 消费者可能需要维护状态; 长时间处理; 仅一次传递

`97 6.6`: __验证系统可靠性__: 
__配置验证__: `VeriablePoducer`, `VeriableConsumer` 首领选举: 如果我停掉首领会发生什么事情？生产者和消费者重新恢复正常状态需要长时间？控制器选举: 重启控制器后系统需要多少时间来恢复状态？依次重启：可以依次重启 broker 而不丢失任何数据吗？不完全首领选举测试：如果依次停止所有副本（确保每个副本都变为不同步的），然后启动一个不同步的 broker 会发生什么？要怎样恢复正常？这样做是可接受的吗？
__应用程序验证__: 客户端从服务器断开连接（系统管理员可以帮忙模拟网络故障); 首领选举; 依次重启 broker; 依次重启消费者；依次重启生产者。
__在生产环境监控可靠性__: 对于生产者来说，最重要的两个可靠性指标是消息的 error-rate 和 retry-rate （聚合过的）。如果这两个指标上升，说明系统出现了问题.
对于消费者来说，最重要的指标是 consumer-lag ，该指标表明了消费者的处理速度与最近提交到分区里的偏移量之间还有多少差距。理想情况下，该指标总是为 0，消费者总能读到最新的消息。
Burrow 是 Linkedln 公司开发的 consumer-lag 检测工具，它可以让这件事情变得容易一些。
端到端的监控系统实现起来很耗费时间， 具有一定挑战性。据我们所知，目前还没有开源的实现。

---

# 七. 构建数据管道

Kafka 为数据管道带来的主要价值在于，它可以作为数据管道各个数据段之间的大型缓冲区, 有效地解耦管道数据的生产者和消费者。

`102 7.1` __构建数据管道时需要考虑的问题__:
__及时性__: Kafka 在这里扮演了一个大型缓冲区的角色，降低了生产者和消费者之间的时间敏感度。
__可靠性__: Kafka 身就支持“至少一次传递”，如果再结合具有业务模型或唯一键特性的外部存储系统， Kafka 也能实现“仅一次传递”。
__高吞吐量和动态吞吐量__: 通过增加额外的消费者或生产者可以实现 Kafka 的伸缩，因此我们可以在数据管道的任何一边进行动态的伸缩，以便满足持续变化的需求。
一个适当规模的集群每秒钟可以处理数百兆的数据，所以根本无需担心数据管道无住满足伸缩性需求。
__数据格式__: Kafka Connect API 与数据格式无关。Avro / XML / JSON / Parquet / csv.
__转换__: ETL 表示提取一转换一加载（Extract-Transform-Load)。ELT 表示提取－加载－转换 Extract-Load-Transform)。
__安全性__: Kafka 支持加密传输数据, 。它还支持认证（通过 SASL 来实现）和授权. Kafka 还提供了审计日志用于跟踪访问记录。
__故障处理能力__: 
__糯合性和灵活性__: 临时数据管道; 元数据丢失; 未端处理.

`105 7.2`: __如何在Connect API 和客户端API 之间作出选择__: 开发一个连接 Kafka 和外部数据存储系统的小应用程序看起来很简单，但其实还有很多细节需要处理，比如数据类型和配置选项，这些无疑加大了开发的复杂性 -- Connect 处理了大部分细节，让你可以专注于数据的传输。

`106 7.3`: __Kafka Connect__: Connect 是 Kafka 部分，它为在 Kafka 和外部数据存储系统之间移动数据提供了一种可靠且可伸缩的方式。
__运行 Connect__: Connect 随着 fk 一起发布，所以无需单独安装。

Connect 使用和深入略过 ...

`116 7.4`: __Connect之外的选择__: 
__用于其他数据存储的摄入框架__: 有些人将 Hadoop 和 ElasticSearch 作为他们数据架构的基础，这些系统都有自己的数据摄入工具。Hadoop 使用了 Flume, ElasticSearch 使用了 Logstash 或 Fluentd 。
如果架构里包含了 Kafka ，并且需要连接大量的源系统和目标系统，那么建议使用 Connect API 作为摄入工具。如果构建的系统是以 Hadoop 或 ElasticSearch 为中心的， Kafka 只是数据的来源之一，那么使用 Flume 或 Logstash 会更合适。
__基于图形界面的ETL工具__: Informatica / Talend / Pentaho / Apache NiFi / StreamSets: 这些 ETL 解决方案都支持将 Kafka 作为数据源和数据池。
我们极力建议将 Kafka 当成是一个支持数据集成（使用 Connect ）、应用集成（使用生产者和消费者）和流式处理的平台。 Kafka 完全可以成为 ETL 工具的替代品。
__流式处理框架__: 几乎所有的流式处理框架都具备从 Kafka 读取数据并将数据写入外部系统的能力。

`117 7.5`: 数据集成系统应该只做一件事情，那就是传递数据。可靠性是数据集成系统唯一一个重要的需求。

---

