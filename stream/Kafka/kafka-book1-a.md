
# 定义

我们认为Kafka是一个流平台：在这个平台上可以发布和订阅数据流，并把它们保存起来、进行处理，这就是构建Kafka的初衷。

Kafka经常会被拿来与现有的技术作比较：企业级消息系统、大数据系统（如Hadoop）和数据集成或 ETL 工具。这里的每一项比较都有一定的道理，但也有失偏颇。

Kafka 有点像消息系统，允许发布和订阅消息流。
  - Kafka以集群的方式运行，可以自由伸缩，处理公司的所有应用程序。
  - 其次，Kafka可以按照你的要求存储数据，保存多久都可以。
  - 流式处理将数据处理的层次提升到了新高度。


Me: 类似传统的消息系统, 如 ActiveMQ, RabbitMQ. 因为它具备消息系统的基本功能 (消息的 发布&订阅), 但是有和他们有很多差异, 比如:
  - 它是分布式的, 可以自由伸缩
  - 其次, 数据是持久化的, 提高了安全性, 保存多久都可以.
  - 另外还提供流处理功能, 可以做一些实时计算 (可以理解成实时版的 Hadoop).
所以可以简单的将 Kafka 理解成是: 消息系统 (发布&订阅) + 分布式 + 持久化 + 流计算.
分布式流平台, Kafka 成为了 个高性能的发布与订阅消息系统。

这个发布与订阅消息系统具有典型的消息系统接口，但从存储层来看，它更像是个日志聚合系统。

# 应用场景

消息系统: 生产者和消费者之间不再有紧密的祸合，也不需要在它们之间建立任何类型的直连。因为生产者不再关心谁在使用数据，也不关心有多少个消费者。

- 活动跟踪: 
- 传递消息: 使用公共组件的好处在于，不需要在多个应用程序上开发重复的功能.
- 度量指标和日志记录: 应用程序定期把度量指标发布到 Kafka 主题上，监控系统或告警系统读取这些消息。日志消息也可以被发布到 Kafka 主题上，然后被路
由到专门的日志搜索系统（比如 ast csearc ）或安全分析应用程序。
- 提交日志: 我们可以把数据库的更新发布到 Kafka 上，应用程序通过监控事件流来接收数据库的实时更新。数据持久化为变更日志提供了缓冲区，也就是说
如果消费者应用程序发生故障，可以通过重放这些日志来恢复系统状态。
- 流处理: 

# 生产和消费

使用推送和拉取模型解耦生产者和消费者.

我们可以增加主题分区的个数，但不能减少分区的个数.

`39`: Kafka 集群通过分区对主题进行横向扩展，所以当有新的 broker 加入集群时，可以通过分区个数来实现集群的负载均衡。

# 生产

`50`: 除了内置的客户端外， Kafka 还提供了二进制连接协议，使得 Kafka 不仅仅局限于在 Java 里使用。

`51`: 生产者概览

`51`: 服务器在收到这些消息时会返回一个响应。如果消息成功写入 Kafka ，就返回 RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量。如果写入失败， 则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，几次之后如果还是失败， 就返回错误信息。

`52`: Kafka 生产者有 3 个必选的属性: `bootstrap.servers`, `key.serializer`, `value.serializer`

`53`: 发送消息主要有以下 3 种方式: `发送并忘记 (fire-and-forget)`, `同步发送`, `异步发送`

`55`: 生产者的配置: `acks`, `buffer.memory`, `compression.type`, `retries`, `batch.size`, `linger.ms`, `client.id`, `max.in.flight.requests.per.connection`, `timeout.ms, request.timeout.ms 和 metadata.fetch.timeout.ms`, `max.block.ms`, `max.request.size`, `receive.buffer bytes 和 send.buffer.bytes`
因为生产者会自动进行重试，所以就没必要在代码逻辑里处理那些可重试的错误。你只需要处理那些不可重试的错误或重试次数超出上限的情况。
`58`: __顺序保证__: 一般来说，如果某些场景要求消息是有序的，那么消息是否写入成功很关键的，所以不建议把 retries 设为 0。可以把 `max.in.flight.requests.per.connection` 设为 1，这样在生产者尝试发送第一批悄息时，就不会有其他的消息发送给 broker 。不过这样会严重影响生产者的吞吐量 ，所以只有在对消息的顺序有严格要求的情况下才能这么做。

`58`: __序列化器__

`64`: __分区__: 如果键值为 null, 并且使用了默认的分区器，那么记录将被随机地发送到主题内各个可用的分区上。分区器使用轮询（Round Robin ）算陆将消息均衡地分布到各个分区上。
如果键不为空，并且使用了默认的分区器，那么 Kafka 会对键进行散列（使用 Kafka 自己的散列算棒，即使升级 Java 版本，散列值也不会发生变化），然后根据散列值把消息映射到特定的分区上。只有在不改变主题分区数量的情况下，键与分区之间的映射才能保持不变。
Partitioner 接口包含了 conflgure, partition, close 这 3 个方法.

# 消费

`73`: 我们要确保在轮询期间所傲的任何处理工作都应该尽快完成。

`74`: 消费者的配置: `fetch.min.bytes`, `fetch.max.wait.ms`, `max.partition.fetch.bytes`, `session.timeout.ms`, `auto.offset.reset`, `enable.auto.commit`, `partition.assignment.strategy`, `client.id`, `max.poll.records`, `receive.buffer.bytes 和 send.buffer.bytes`

`85`: __如何退出__

`86`: __反序列化器__

# 消费 - 再平衡

`70`: 在主题发生变化时, 比如管理员添加了新的分区，会发生分区重分配。分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。再均衡非常重要， 它为消费者群组带来了高可用性和伸缩性。
在再均衡期间，消费者无陆读取消息，造成整个群组一小段时间的不可用。

`70`: 消费者通过向被指派为群组协调器的 broker （不同的群组可以有不同的协调器）发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。消费者会在轮询消息（为了获取消息）或提交偏移量时发送心跳。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发一次再均衡。
如果一个消费者发生崩愤，井停止读取消息，群组协调器会等待几秒钟，确认它死亡了才触发再均衡。

`71`: 如果你使用的是较新版本的 Kafka ，并且需要处理耗费较长时间的消息，只需要加大 `max.poll.interval.ms` 的值来增加轮均间隔的时长.

`71`: 分配分区是怎样的一个过程 ?

`82`: __再均衡监昕器__: `ConsumerRebalanceListener.onPartitionsRevoked()`

# 消费 - 偏移量

`76`: __提交__: 我们把更新分区当前位置的操作叫作提交. 那么消费者是如何提交偏移量的呢？消费者往一个叫作 consumer_offset 特殊主题发送消息，消息里包含每个分区的偏移量.
如果提交的偏移量小于客户端处理的最后一个消息的偏移量 ，那么处于两个偏移量之间的消息就会被重复处理. 如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失.
所以，处理偏移量的方式对客户端会有很大的影响。
`77`: __自动提交__: 提交时间间隔 `auto.commit.interval.ms` 控制，默认值是 5s。自动提交虽然方便, 不过并没有为开发者留有余地来避免重复处理消息。
`78`: __提交当前偏移量__
`78`: __异步提交__
`80`: __同步和异步组合提交__
`80`: __提交特定的偏移量__

`83`: __从特定偏移量处开始处理记录__: 通过把偏移量和记录保存到同一个外部系统来实现单次语义可以有很多种方式，不过它们都需要结合使用 ConsumerRebalancelistener() 和 seek() 方法来确保能够及时保存偏移量，并保证消费者总是能够从正确的位置开始读取消息。


# ZooKeeper

每个 ZooKeeper 节点的含义.
不建议一个群组包含超 7 个节点，因为 Zookeeper 使用了一致性协议，节点过多会降低整个群组的性能。

Kafka 集群里使用 root 路径是 种最佳实践。 ZooKeep 群组可以共享给其他应用程序，即使还有其他 Kafka 集群存在， 不会产生冲突。: `zookeeper.connect=10.105.231.204:2181,10.105.231.204:2182,10.105.231.204:2183`

在很多部署环境里，会让多个 Kafka 集群共享一个 Zookeep 群组（每个集群使用一个 chroot 路径）。

`48`: Kafka 0.9.0.0 版本之前，除了 broker 之外， 消费者也会使用 Zookeeper 保存一些信息，比如消费者群组的信息、 主题信息、消费分区的偏移量（在消费者群组里发生失效转移时会用到）。到了 0.9.0.0 版本， Kafka 引入了一个新的消费者接口，允许 broker 直接维护这些信息。
消费者将会为每个消费的分区往 Zookeeper 写入一次偏移量。合理的提交间隔是 1 分钟，对 ZooKeeper 有压力.
建议使用最新版本的 Kafka ，让消费者把偏移量提交到 Kafka 服务器上，消除对 Zookeep 的依赖.

虽然多个 Kafka 集群可以共享 Zookeeper 群组，但如果有可能的话，不建议 把 Zooeeper 共享给其他应用程序。Kafka 对 Zookeeper 的延迟和超时比较敏感，Zookeeper 群组之间的一个通信异常就可能导致 Kafka 服务器出现无怯预测的行为。
其他的应用程序因重度使用或进行不恰当的操作给 Zookeeper 群组带来压力，所以最好让它们使用自己的 Zookeeper 群组.

# 持久化数据存储

每个主题可以设置单独的保留规则，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。

主题可以配置自己的保留策略，可以将悄息保留到不再使用它们为止。例如，用于跟踪用户活动的数据可能需要保留几天，而应用程序的度量指标可能只需要保留几个小时。
可以通过配置把主题当作紧凑型日志， 只有最后 个带有特定键的消息会被保留下来。

消费者可能会因为处理速度慢或突发的流量高峰导致无陆及时读取消息，而持久化数据可以保证数据不会丢失。

消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵塞在生产者端 消费者可以被关闭，但消息会继续保留在 Kafka 里。消费者可以从上次中断的地方继续处理消息。

# 性能

通过系统优化实现高吞吐量, 系统可随着数据流的增长进行横向扩展。

根据特定的硬件及其性能特征，单个 broker 可以轻松处理数千个分区以及每秒百万级的消息量。

通过横向扩展生产者、消费者和 broker, Kafka 可以轻松处理巨大的消息流。在处理大量数据的同时，它还能保证亚秒级的消息延迟。

# 优化

`38`: `num.recovery.threads.per.data.dir`: 对于如下几种情况， Kafka 会使用可配置的线程来处理日志片段
`38`: `auto.create.topics.enable`: 很多时候，这些行为都是非预期的。而且，根据 Kafka 议，如果一个主题不先被创建，根本无法知道它是否已经存在。

新版本如果要对参数进行覆盖，需要使用管理工具。为每个主题单独配置部分参数，比如分区个数和数据保留策略。

`39`: 如何选定分区数?
- 主题需要达到多大的吞吐量? 例如，是希望每秒钟写入 100 KB 还是 1GB?

`41`: `log.retention.ms` + `log.segment.bytes` / `log.segment.ms`

`41`: `message.max.bytes`: 限制单个消息的大小, 该参数指的是压缩后的消息大小, 默认值是 1000000, 也就是 lMB.

`42`: __磁盘吞吐量__: 生产者客户端的性能直接受到服务器端磁盘吞吐量 影响。生产者生成的消息必须被提交到服务器保存，大多数客户端在发送消息之后会一直等待，直到至少有一个服务器确认消息已经成功提交为止，也就是说，磁盘写入速度越快，生成消息的延迟就越低。
在同一个服务器上使用多个机械硬盘，可以设置多个数据目录 ，或者把它们设置成磁盘阵列，这样可以提升机械硬盘的性能。
固态硬盘的查找和访问速度都很快，提供了最好的性能。
__磁盘容量__
__内存__: 磁盘性能影响生产者, 而内存影响消费者. 消费者一般从分区尾部读取消息，如果有生产者存在, 就紧跟在生产者后面。在这种情况下，消费者读取的消息会直接存放在系统的页面缓存里，这比从磁盘上重新读取要快得多 (`零拷贝`). 运行 Kafka JVM 不需要太大的内存，剩余的系统内存可以用作页面缓存，或者用来缓存正在使用中的日志片段。
__网络__: 生产, 消费, 集群复制, 镜像都会消耗网络.
__CPU__: 与磁盘和内存相比， Kafka 对计算处理能力的要求相对较低. 客户端为优化网络和磁盘空间，会对消息进行压缩. 服务器需对消息进行批量解压，设置偏移量，然后重新进行批量压缩，再保存到磁盘上.

`44`: __需要多少个broker__: 需要多少磁盘空间; 集群处理请求的能力. 因磁盘吞吐量低和系统内存不足造成的性能问题，也可以通过扩展多个 broker 来解决。

`45`: __操作系统调优__:
  - __虚拟内存__, 对于大多数依赖吞吐量的应用程序来说，要尽量避免内存交换。内存页和磁盘之间的交换 Kafka 各方面的性能都有重大影响。Kafka 大量地使用系统页面缓存，如果虚拟内存被交换到磁盘，说明已经没有多余内存可以分配给页面缓存了。要优先考虑减小页面缓存，而不是进行内存交换。... `vl'l.swapp"i.ness`=1
  - __磁盘__: EXT4
  - __网络__: 默认情况下，系统内核没有针对快速的大流量网络传输进行优化， 所以对于应用程序来说，一般需要对 Linux 系统的网络技进行调优，以实现对大流量的支持。可以对分配给 socket 读写缓冲区的内存大小作出调整，这样可以显著提升网络的传输性能。

__数据中心布局__: 在为 broker 增加新的分区时， broker 并无怯获知机架的信息。所以，最好把集群的 broker 安装在不同的机架上，至少不要让它们共享可能出现单点故障的基础设施，比如电源和网络。 

__ZooKeeper__: 。对于一个包含多个节点的 Zookeeper 群组来说， Kafka 集群的这些流量并不算多，那些写操作只是用于构造消费者群组或集群本身。

# 生产应用

在软件工程里，条条道路通罗马，每一个问题都有多种解决方案。这只是其中的一种方案，可能并不是完美的, 例如增加了架构的复杂度, 提高了风险.

